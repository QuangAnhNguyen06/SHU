{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import lr_scheduler\n",
    "import func\n",
    "\n",
    "folder_path = \"F:/code/barlow/UR5\"\n",
    "file_pairs = func.load_file_pairs(folder_path)\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "CROP_TO = 32\n",
    "SEED = 200\n",
    "\n",
    "PROJECT_DIM = 2048\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_500_similar, random_500_dissimilar, remaining_similar, remaining_dissimilar = func.split_and_shuffle_pairs(file_pairs, folder_path)\n",
    "\n",
    "def process_data(data_list):\n",
    "    return [\n",
    "        [func.read_jpg_files(jpg_path), func.read_and_parse_npy_file(npy_path)]\n",
    "        for jpg_path, npy_path in data_list\n",
    "    ]\n",
    "\n",
    "xtrain1 = process_data(random_500_similar)\n",
    "xtrain2 = process_data(random_500_dissimilar)\n",
    "xtest1 = process_data(remaining_similar)\n",
    "xtest2 = process_data(remaining_dissimilar)\n",
    "\n",
    "# label 1 - similar, 0 - disimilar\n",
    "ytrain1 = [1] * 500\n",
    "ytrain2 = [0] * 500\n",
    "ytest1 = [1] *79\n",
    "ytest2 = [0] *79\n",
    "\n",
    "y_train = ytrain1 + ytrain2\n",
    "y_test = ytest1 + ytest2\n",
    "x_train = xtrain1 + xtrain2\n",
    "x_test = xtest1 + xtest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "t1 = np.array([item[0] for item in x_train])  # Lấy phần ảnh\n",
    "t2 = np.array([item[1] for item in x_train])  # Lấy phần npy vector\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(((t1, t2),y_train))\n",
    "train_ds = train_ds.map(\n",
    "    lambda inputs, y: (func.combine_data(*inputs), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t3 = np.array([item[0] for item in x_test])  # Lấy phần ảnh\n",
    "t4 = np.array([item[1] for item in x_test])  # Lấy phần npy vector\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(((t3, t4),y_test))\n",
    "test_ds = test_ds.map(\n",
    "    lambda inputs, y: (func.combine_data(*inputs), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "test_ds = (\n",
    "    test_ds\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_encoder(input_dim):\n",
    "    inputs = tf.keras.Input(shape=(input_dim,))\n",
    "\n",
    "    # x1 = CONVO(inputs[...])\n",
    "    # x2 = CONVO(inputs[-8])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=None)(x)  # Projection head\n",
    "    return tf.keras.Model(inputs, x)\n",
    "\n",
    "# Tạo encoder mới\n",
    "mlp_encoder = create_mlp_encoder(input_dim=16392)\n",
    "# Sử dụng encoder MLP cho Barlow Twins\n",
    "barlow_twins = func.BarlowTwins(encoder=mlp_encoder)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9)\n",
    "barlow_twins.compile(optimizer=optimizer)\n",
    "# barlow_twins.load_weights('bl.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = tf.keras.Model(\n",
    "    inputs=barlow_twins.encoder.input,\n",
    "    outputs=barlow_twins.encoder.layers[-1].output  # output từ lớp Dense(128)\n",
    ")\n",
    "# Freeze \n",
    "backbone.trainable = False\n",
    "\n",
    "# add classifier\n",
    "inputs = tf.keras.layers.Input(shape=(16392,))\n",
    "x = backbone(inputs, training=False)\n",
    "\n",
    "#outputs = tf.keras.layers.Dense(10, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"relu\")(x)\n",
    "\n",
    "test_model = tf.keras.Model(inputs, outputs, name=\"test_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle train_ds vs test_ds\n",
    "seed = 226\n",
    "train_ds = train_ds.shuffle(buffer_size=10, seed=seed, reshuffle_each_iteration=True)\n",
    "test_ds = test_ds.shuffle(buffer_size=10, seed=seed, reshuffle_each_iteration=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7774 - loss: 3.5880 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 4.0413 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 4.2490 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 3.9188 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 3.1233 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7594 - loss: 3.8775 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7633 - loss: 3.8159 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 3.6654 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7723 - loss: 3.6693 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 4.3642 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7609 - loss: 3.8538 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 4.1059 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 3.6243 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7343 - loss: 4.2831 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 3.5616 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 3.5593 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7483 - loss: 4.0561 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7574 - loss: 3.9097 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 3.6801 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7104 - loss: 4.6682 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 4.4216 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7413 - loss: 4.1705 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7386 - loss: 4.2135 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 4.6355 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 4.5091 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 3.9299 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7986 - loss: 3.2466 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7743 - loss: 3.6373 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7730 - loss: 3.6585 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 4.0366 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 4.2516 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 4.5117 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 4.1920 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 3.5230 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7836 - loss: 3.4872 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7617 - loss: 3.8409 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 3.9174 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7436 - loss: 4.1335 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7755 - loss: 3.6184 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 4.0228 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 3.9712 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 3.5106 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 3.6171 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 2.9844 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7609 - loss: 3.8534 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7322 - loss: 4.3162 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7878 - loss: 3.4202 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7629 - loss: 3.8221 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 4.0227 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7372 - loss: 4.2361 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 3.9310 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 3.9772 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7416 - loss: 4.1656 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7701 - loss: 3.7053 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7540 - loss: 3.9652 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7478 - loss: 4.0643 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 3.5935 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 3.9369 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 4.3123 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 3.4415 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7272 - loss: 4.3967 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6951 - loss: 4.9143 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 3.0756 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7280 - loss: 4.3837 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 3.5994 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 3.9982 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7488 - loss: 4.0486 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7643 - loss: 3.7986 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 3.5313 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 3.9091 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7577 - loss: 3.9047 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7706 - loss: 3.6982 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 4.0680 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7545 - loss: 3.9566 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 3.5503 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7433 - loss: 4.1381 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7533 - loss: 3.9765 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7372 - loss: 4.2356 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7739 - loss: 3.6451 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 3.4908 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7849 - loss: 3.4666 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7622 - loss: 3.8331 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 4.3010 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 4.3470 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 3.7210 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 3.3015 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 4.0037 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7710 - loss: 3.6905 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7660 - loss: 3.7717 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 4.2520 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7460 - loss: 4.0945 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 4.3854 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7902 - loss: 3.3823 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 4.0638 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7716 - loss: 3.6819 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7386 - loss: 4.2138 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 4.0897 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 4.1477 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7446 - loss: 4.1167 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 3.3224 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3081 - loss: 11.1527    \n",
      "Test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "test_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.00005, momentum=0.9)\n",
    ")\n",
    "\n",
    "history = test_model.fit(\n",
    "    train_ds, validation_data=test_ds, epochs=100\n",
    ")\n",
    "\n",
    "_, test_acc = test_model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Sample 0: Predicted Label = 1, True Label = 1\n",
      "Sample 1: Predicted Label = 1, True Label = 1\n",
      "Sample 2: Predicted Label = 1, True Label = 1\n",
      "Sample 3: Predicted Label = 1, True Label = 1\n",
      "Sample 4: Predicted Label = 1, True Label = 1\n",
      "Sample 5: Predicted Label = 1, True Label = 1\n",
      "Sample 6: Predicted Label = 1, True Label = 1\n",
      "Sample 7: Predicted Label = 1, True Label = 1\n",
      "Sample 8: Predicted Label = 1, True Label = 1\n",
      "Sample 9: Predicted Label = 1, True Label = 1\n",
      "Sample 10: Predicted Label = 1, True Label = 1\n",
      "Sample 11: Predicted Label = 1, True Label = 1\n",
      "Sample 12: Predicted Label = 1, True Label = 1\n",
      "Sample 13: Predicted Label = 1, True Label = 1\n",
      "Sample 14: Predicted Label = 1, True Label = 1\n",
      "Sample 15: Predicted Label = 1, True Label = 1\n",
      "Sample 16: Predicted Label = 1, True Label = 1\n",
      "Sample 17: Predicted Label = 1, True Label = 1\n",
      "Sample 18: Predicted Label = 1, True Label = 1\n",
      "Sample 19: Predicted Label = 1, True Label = 1\n",
      "Sample 20: Predicted Label = 1, True Label = 1\n",
      "Sample 21: Predicted Label = 1, True Label = 1\n",
      "Sample 22: Predicted Label = 1, True Label = 1\n",
      "Sample 23: Predicted Label = 1, True Label = 1\n",
      "Sample 24: Predicted Label = 1, True Label = 1\n",
      "Sample 25: Predicted Label = 1, True Label = 1\n",
      "Sample 26: Predicted Label = 1, True Label = 1\n",
      "Sample 27: Predicted Label = 1, True Label = 1\n",
      "Sample 28: Predicted Label = 1, True Label = 1\n",
      "Sample 29: Predicted Label = 1, True Label = 1\n",
      "Sample 30: Predicted Label = 1, True Label = 1\n",
      "Sample 31: Predicted Label = 1, True Label = 1\n",
      "Sample 32: Predicted Label = 1, True Label = 1\n",
      "Sample 33: Predicted Label = 1, True Label = 1\n",
      "Sample 34: Predicted Label = 1, True Label = 1\n",
      "Sample 35: Predicted Label = 1, True Label = 1\n",
      "Sample 36: Predicted Label = 1, True Label = 1\n",
      "Sample 37: Predicted Label = 1, True Label = 1\n",
      "Sample 38: Predicted Label = 1, True Label = 1\n",
      "Sample 39: Predicted Label = 1, True Label = 1\n",
      "Sample 40: Predicted Label = 1, True Label = 1\n",
      "Sample 41: Predicted Label = 1, True Label = 1\n",
      "Sample 42: Predicted Label = 1, True Label = 1\n",
      "Sample 43: Predicted Label = 1, True Label = 1\n",
      "Sample 44: Predicted Label = 1, True Label = 1\n",
      "Sample 45: Predicted Label = 1, True Label = 1\n",
      "Sample 46: Predicted Label = 1, True Label = 1\n",
      "Sample 47: Predicted Label = 1, True Label = 1\n",
      "Sample 48: Predicted Label = 1, True Label = 1\n",
      "Sample 49: Predicted Label = 1, True Label = 1\n",
      "Sample 50: Predicted Label = 1, True Label = 1\n",
      "Sample 51: Predicted Label = 1, True Label = 1\n",
      "Sample 52: Predicted Label = 1, True Label = 1\n",
      "Sample 53: Predicted Label = 1, True Label = 1\n",
      "Sample 54: Predicted Label = 1, True Label = 1\n",
      "Sample 55: Predicted Label = 1, True Label = 1\n",
      "Sample 56: Predicted Label = 1, True Label = 1\n",
      "Sample 57: Predicted Label = 1, True Label = 1\n",
      "Sample 58: Predicted Label = 1, True Label = 1\n",
      "Sample 59: Predicted Label = 1, True Label = 1\n",
      "Sample 60: Predicted Label = 1, True Label = 1\n",
      "Sample 61: Predicted Label = 1, True Label = 1\n",
      "Sample 62: Predicted Label = 1, True Label = 1\n",
      "Sample 63: Predicted Label = 1, True Label = 1\n",
      "Sample 64: Predicted Label = 1, True Label = 0\n",
      "Sample 65: Predicted Label = 1, True Label = 0\n",
      "Sample 66: Predicted Label = 1, True Label = 0\n",
      "Sample 67: Predicted Label = 1, True Label = 0\n",
      "Sample 68: Predicted Label = 1, True Label = 0\n",
      "Sample 69: Predicted Label = 1, True Label = 0\n",
      "Sample 70: Predicted Label = 1, True Label = 0\n",
      "Sample 71: Predicted Label = 1, True Label = 0\n",
      "Sample 72: Predicted Label = 1, True Label = 0\n",
      "Sample 73: Predicted Label = 1, True Label = 0\n",
      "Sample 74: Predicted Label = 1, True Label = 0\n",
      "Sample 75: Predicted Label = 1, True Label = 0\n",
      "Sample 76: Predicted Label = 1, True Label = 0\n",
      "Sample 77: Predicted Label = 1, True Label = 0\n",
      "Sample 78: Predicted Label = 1, True Label = 0\n",
      "Sample 79: Predicted Label = 1, True Label = 0\n",
      "Sample 80: Predicted Label = 1, True Label = 0\n",
      "Sample 81: Predicted Label = 1, True Label = 0\n",
      "Sample 82: Predicted Label = 1, True Label = 0\n",
      "Sample 83: Predicted Label = 1, True Label = 0\n",
      "Sample 84: Predicted Label = 1, True Label = 0\n",
      "Sample 85: Predicted Label = 1, True Label = 0\n",
      "Sample 86: Predicted Label = 1, True Label = 0\n",
      "Sample 87: Predicted Label = 1, True Label = 0\n",
      "Sample 88: Predicted Label = 1, True Label = 0\n",
      "Sample 89: Predicted Label = 1, True Label = 0\n",
      "Sample 90: Predicted Label = 1, True Label = 0\n",
      "Sample 91: Predicted Label = 1, True Label = 0\n",
      "Sample 92: Predicted Label = 1, True Label = 0\n",
      "Sample 93: Predicted Label = 1, True Label = 0\n",
      "Sample 94: Predicted Label = 1, True Label = 0\n",
      "Sample 95: Predicted Label = 1, True Label = 0\n",
      "Sample 96: Predicted Label = 1, True Label = 1\n",
      "Sample 97: Predicted Label = 1, True Label = 1\n",
      "Sample 98: Predicted Label = 1, True Label = 1\n",
      "Sample 99: Predicted Label = 1, True Label = 1\n",
      "Sample 100: Predicted Label = 1, True Label = 1\n",
      "Sample 101: Predicted Label = 1, True Label = 1\n",
      "Sample 102: Predicted Label = 1, True Label = 1\n",
      "Sample 103: Predicted Label = 1, True Label = 1\n",
      "Sample 104: Predicted Label = 1, True Label = 1\n",
      "Sample 105: Predicted Label = 1, True Label = 1\n",
      "Sample 106: Predicted Label = 1, True Label = 1\n",
      "Sample 107: Predicted Label = 1, True Label = 1\n",
      "Sample 108: Predicted Label = 1, True Label = 1\n",
      "Sample 109: Predicted Label = 1, True Label = 1\n",
      "Sample 110: Predicted Label = 1, True Label = 1\n",
      "Sample 111: Predicted Label = 1, True Label = 0\n",
      "Sample 112: Predicted Label = 1, True Label = 0\n",
      "Sample 113: Predicted Label = 1, True Label = 0\n",
      "Sample 114: Predicted Label = 1, True Label = 0\n",
      "Sample 115: Predicted Label = 1, True Label = 0\n",
      "Sample 116: Predicted Label = 1, True Label = 0\n",
      "Sample 117: Predicted Label = 1, True Label = 0\n",
      "Sample 118: Predicted Label = 1, True Label = 0\n",
      "Sample 119: Predicted Label = 1, True Label = 0\n",
      "Sample 120: Predicted Label = 1, True Label = 0\n",
      "Sample 121: Predicted Label = 1, True Label = 0\n",
      "Sample 122: Predicted Label = 1, True Label = 0\n",
      "Sample 123: Predicted Label = 1, True Label = 0\n",
      "Sample 124: Predicted Label = 1, True Label = 0\n",
      "Sample 125: Predicted Label = 1, True Label = 0\n",
      "Sample 126: Predicted Label = 1, True Label = 0\n",
      "Sample 127: Predicted Label = 1, True Label = 0\n",
      "Sample 128: Predicted Label = 1, True Label = 0\n",
      "Sample 129: Predicted Label = 1, True Label = 0\n",
      "Sample 130: Predicted Label = 1, True Label = 0\n",
      "Sample 131: Predicted Label = 1, True Label = 0\n",
      "Sample 132: Predicted Label = 1, True Label = 0\n",
      "Sample 133: Predicted Label = 1, True Label = 0\n",
      "Sample 134: Predicted Label = 1, True Label = 0\n",
      "Sample 135: Predicted Label = 1, True Label = 0\n",
      "Sample 136: Predicted Label = 1, True Label = 0\n",
      "Sample 137: Predicted Label = 1, True Label = 0\n",
      "Sample 138: Predicted Label = 1, True Label = 0\n",
      "Sample 139: Predicted Label = 1, True Label = 0\n",
      "Sample 140: Predicted Label = 1, True Label = 0\n",
      "Sample 141: Predicted Label = 1, True Label = 0\n",
      "Sample 142: Predicted Label = 1, True Label = 0\n",
      "Sample 143: Predicted Label = 1, True Label = 0\n",
      "Sample 144: Predicted Label = 1, True Label = 0\n",
      "Sample 145: Predicted Label = 1, True Label = 0\n",
      "Sample 146: Predicted Label = 1, True Label = 0\n",
      "Sample 147: Predicted Label = 1, True Label = 0\n",
      "Sample 148: Predicted Label = 1, True Label = 0\n",
      "Sample 149: Predicted Label = 1, True Label = 0\n",
      "Sample 150: Predicted Label = 1, True Label = 0\n",
      "Sample 151: Predicted Label = 1, True Label = 0\n",
      "Sample 152: Predicted Label = 1, True Label = 0\n",
      "Sample 153: Predicted Label = 1, True Label = 0\n",
      "Sample 154: Predicted Label = 1, True Label = 0\n",
      "Sample 155: Predicted Label = 1, True Label = 0\n",
      "Sample 156: Predicted Label = 1, True Label = 0\n",
      "Sample 157: Predicted Label = 1, True Label = 0\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test dataset\n",
    "predictions = test_model.predict(test_ds)\n",
    "\n",
    "# Extract the true labels from the test dataset\n",
    "true_labels = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Print predictions and true labels\n",
    "for i, prediction in enumerate(predictions):\n",
    "    predicted_label = np.argmax(prediction)  # Get the predicted class index\n",
    "    print(f\"Sample {i}: Predicted Label = {predicted_label}, True Label = {true_labels[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
